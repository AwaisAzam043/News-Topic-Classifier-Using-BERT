{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# BERT News Topic Classifier — AG News (End‑to‑End)\n\nThis mini‑project fine‑tunes **bert-base-uncased** on the **AG News** dataset, evaluates with **accuracy** and **macro F1**, and deploys a lightweight **Gradio** demo for live predictions.\n\n---\n\n## 📦 Project Structure\n\n```\nbert-agnews/\n├── train.py              # Fine-tune & evaluate BERT\n├── app.py                # Gradio demo for live inference\n├── requirements.txt      # Dependencies\n└── README.md             # (optional) Notes & tips\n```\n\n---\n\n## 🔧 requirements.txt\n\n```\ntransformers>=4.44.0\ndatasets>=2.19.0\ntorch>=2.1.0\nscikit-learn>=1.1.0\ngradio>=4.44.0\naccelerate>=0.33.0\nnumpy>=1.24.0\n```\n\n> **Tip:** If using GPU, install the appropriate CUDA build of PyTorch from pytorch.org.\n\n---\n\n## 🧠 train.py (fine‑tune + evaluate + save)\n\n```python","metadata":{}},{"cell_type":"code","source":"! pip install -q --upgrade transformers datasets accelerate\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport os\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    DataCollatorWithPadding,\n    AutoModelForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n)\nfrom sklearn.metrics import accuracy_score, f1_score\nimport numpy as np\nimport torch\n\nMODEL_NAME = \"bert-base-uncased\"\nOUTPUT_DIR = \"outputs/bert-agnews\"\nSAVE_DIR = \"models/bert-agnews\"\nSEED = 42\n\n# 1) Load AG News\n# The HF \"ag_news\" dataset has 4 classes: 0=World, 1=Sports, 2=Business, 3=Sci/Tech\nraw = load_dataset(\"ag_news\")\n\n# 2) Build a clean text field if needed (some variants have 'text'; others have 'title'/'description')\n\ndef build_text(example):\n    if \"text\" in example and example[\"text\"]:\n        example[\"clean_text\"] = example[\"text\"]\n    else:\n        title = example.get(\"title\", \"\") or \"\"\n        desc = example.get(\"description\", \"\") or \"\"\n        example[\"clean_text\"] = (title + \". \" + desc).strip()\n    return example\n\nraw = raw.map(build_text)\n\n# 3) Tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\nmax_length = 256\n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"clean_text\"],\n        truncation=True,\n        max_length=max_length,\n    )\n\ntok = raw.map(tokenize, batched=True, remove_columns=[c for c in raw[\"train\"].column_names if c not in [\"label\"]])\n\n# 4) Label maps\nid2label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\nlabel2id = {v: k for k, v in id2label.items()}\n\n# 5) Model\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME, num_labels=4, id2label=id2label, label2id=label2id\n)\n\n# 6) Data collator (dynamic padding)\ncollator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n# 7) Metrics\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    acc = accuracy_score(labels, preds)\n    f1 = f1_score(labels, preds, average=\"macro\")\n    return {\"accuracy\": acc, \"f1_macro\": f1}\n\n# 8) Training args\nargs = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=32,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"accuracy\",\n    seed=SEED,\n    fp16=torch.cuda.is_available(),\n    report_to=[]  # no wandb by default\n)\n\n# 9) Trainer\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tok[\"train\"],\n    eval_dataset=tok[\"test\"],  # AG News doesn't ship a validation split; we eval on test for simplicity\n    tokenizer=tokenizer,\n    data_collator=collator,\n    compute_metrics=compute_metrics,\n)\n\n# 10) Train\ntrainer.train()\n\n# 11) Evaluate (accuracy & F1)\nmetrics = trainer.evaluate(tok[\"test\"])  # returns dict with loss, accuracy, f1_macro\nprint(\"\\n*** Test Metrics ***\")\nfor k, v in metrics.items():\n    if isinstance(v, float):\n        print(f\"{k}: {v:.4f}\")\n    else:\n        print(f\"{k}: {v}\")\n\n# 12) Save final model & tokenizer\nos.makedirs(SAVE_DIR, exist_ok=True)\ntrainer.save_model(SAVE_DIR)\ntokenizer.save_pretrained(SAVE_DIR)\nprint(f\"\\nSaved fine-tuned model to: {SAVE_DIR}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:48:34.314668Z","iopub.execute_input":"2025-09-03T05:48:34.315234Z","iopub.status.idle":"2025-09-03T05:49:19.721151Z","shell.execute_reply.started":"2025-09-03T05:48:34.315195Z","shell.execute_reply":"2025-09-03T05:49:19.719672Z"}},"outputs":[{"name":"stderr","text":"2025-09-03 05:48:43.450537: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1756878523.496467     150 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1756878523.506332     150 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb541edcf46243fda2f4121f2f592f3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1d876702f5443f68895e774d6cfe1c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52bd29e1d0a347029870877d41df344a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fae56b0a2e0d49acbe71f7ce208407f1"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_150/1265657912.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# 8) Training args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m args = TrainingArguments(\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_DIR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mevaluation_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'"],"ename":"TypeError","evalue":"TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"## 🚀 app.py (Gradio live demo)\n\n\nimport torch\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport gradio as gr\n\nMODEL_DIR = \"models/bert-agnews\"  # path saved by train.py\nid2label = {0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tech\"}\n\n# Load once\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR).to(device)\nmodel.eval()\n\n@torch.inference_mode()\ndef predict(text: str):\n    if not text or not text.strip():\n        return {\"label\": \"\", \"scores\": {}}\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256).to(device)\n    outputs = model(**enc)\n    probs = torch.softmax(outputs.logits, dim=-1).detach().cpu().numpy()[0]\n    top_id = int(np.argmax(probs))\n    result = {id2label[i]: float(probs[i]) for i in range(len(probs))}\n    return {\"label\": id2label[top_id], \"scores\": result}\n\n# Gradio UI\nwith gr.Blocks(title=\"BERT News Topic Classifier\") as demo:\n    gr.Markdown(\"\"\"\n    # 📰 BERT News Topic Classifier\n    Enter a news headline or short blurb to predict its topic.\n    \"\"\")\n\n    inp = gr.Textbox(label=\"News headline\", placeholder=\"e.g., Apple unveils new AI features for iPhone...\")\n    btn = gr.Button(\"Classify\")\n    out_label = gr.Label(label=\"Predicted Topic\")\n    out_scores = gr.JSON(label=\"Class Probabilities\")\n\n    def _run(text):\n        res = predict(text)\n        return res[\"label\"], res[\"scores\"]\n\n    btn.click(_run, inputs=inp, outputs=[out_label, out_scores])\n\n    gr.Examples(\n        examples=[\n            [\"Stocks surge as central bank hints at rate cuts\"],\n            [\"NASA announces new mission to explore asteroid belt\"],\n            [\"Premier League champions sign star striker\"],\n            [\"UN condemns violence amid escalating border tensions\"],\n        ],\n        inputs=inp,\n    )\n\nif __name__ == \"__main__\":\n    demo.launch()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n## ▶️ How to Run\n\n```bash\n# 1) Create environment (optional but recommended)\npython -m venv .venv && source .venv/bin/activate  # (Linux/Mac)\n# on Windows: python -m venv .venv && .venv\\Scripts\\activate\n\n# 2) Install deps\npip install -r requirements.txt\n\n# 3) Fine-tune + evaluate\npython train.py\n# You’ll see accuracy and macro F1 on AG News test set printed at the end.\n\n# 4) Launch the demo\npython app.py\n# Open the local URL that Gradio prints in the terminal.\n```\n\n---\n\n## 🧪 Notes on Metrics\n\n* **Accuracy**: overall correctness across 4 classes.\n* **Macro F1**: averages F1 across classes equally (robust when classes are imbalanced).\n\n> Expect \\~93–95% **accuracy** on AG News with this setup (varies with seed/epochs/GPU).\n\n---\n\n## ⚙️ Tweaks & Tips\n\n* **Faster training**: try `distilbert-base-uncased`.\n* **Longer texts**: increase `max_length` (trade‑off: speed/memory).\n* **More epochs**: 3–5 often helps; watch validation metrics for overfitting.\n* **Class weights**: AG News is fairly balanced; usually not needed.\n* **Export**: package `models/bert-agnews` as a folder for deployment or push to Hugging Face Hub.\n\n---\n\n## ✅ Skills Practiced\n\n* Tokenization & preprocessing with **Hugging Face Datasets**\n* Fine‑tuning **BERT** for sequence classification\n* Evaluating with **accuracy** & **macro F1**\n* Lightweight deployment via **Gradio**","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}